# INTERNSHIP
COMPANY NAME- CODTECT IT SOLUTION
NAME -NALKAR PRATIKSHA DATTATRAY 
INTERN ID-CT04WT198
DOMAIN- DATA ANALYATICS
DURATION - 4 WEEKS
MENTOR- NEELA SANTOSH KUMAR

##During my internship at CodTech, I completed four major tasks that helped enhance my practical skills in big data analysis, machine learning, NLP text processing, and dashboard development. I used tools like Jupyter Notebook, various Python libraries, Natural Language Processing (NLP) techniques, and Power BI for these tasks.

Task 1: Big Data Analysis Using PySpark
For the big data analysis task, I worked with a large dataset and used PySpark inside Jupyter Notebook. PySpark is a powerful library for handling and analyzing big data efficiently. I loaded the dataset, performed data cleaning, handled missing values, and carried out exploratory data analysis (EDA) to understand the dataset's characteristics. I demonstrated how scalable processing can be achieved even with large datasets by using distributed computing through Spark. The main insights from this task included data trends, outlier detection, and summarization. This task helped me understand the importance of scalability when working with massive amounts of data.

Task 2: Predictive Analysis Using Machine Learning
In the second task, I built a predictive model using machine learning. I used Python libraries such as pandas, scikit-learn, and matplotlib for this purpose. After selecting relevant features, I performed data splitting (into training and testing sets) and applied a classification model. I experimented with algorithms like Random Forest and Logistic Regression to predict outcomes based on the data. I evaluated the model using metrics like accuracy, precision, recall, and F1-score. Jupyter Notebook was extremely useful for documenting each step clearly with code cells and markdown explanations. This task helped me understand the complete machine learning workflowâ€”from feature engineering to model evaluation.

Task 3: Dashboard Development Using Power BI
For the dashboard development task, I used Microsoft Power BI to create an interactive dashboard from a processed dataset. I imported the dataset into Power BI and created various visualizations such as bar charts, pie charts, and trend lines. I used features like slicers, filters, and drill-downs to make the dashboard interactive and user-friendly. The dashboard provided clear actionable insights into the dataset's trends and patterns. This task taught me the importance of effective data visualization and how crucial dashboards are in presenting complex data simply to stakeholders for decision-making.

Task 4: Sentiment Analysis Using NLP
The fourth task involved performing sentiment analysis on textual data. I used Python libraries such as NLTK, TextBlob, and scikit-learn. First, I carried out data preprocessing steps like text cleaning, tokenization, removal of stopwords, and stemming/lemmatization. After cleaning the data, I built a sentiment classification model to detect positive, negative, or neutral sentiments in the text. Techniques like TF-IDF vectorization were used to convert text into numerical features. The insights from this task revealed public sentiment trends that could be valuable for businesses or marketing strategies. Through this, I gained a strong understanding of NLP techniques and the challenges associated with textual data analysis.

How These Tasks Were Helpful:
Skill Development: These tasks improved my technical skills in Python programming, data preprocessing, machine learning, big data tools like PySpark, and visualization platforms like Power BI.
Real-world Experience: Working on real datasets provided practical experience in facing challenges such as missing values, noisy data, and model optimization.
Understanding End-to-End Projects: I learned how a data science project flows from data collection to data cleaning, modeling, and visualization.
Better Collaboration Readiness: By using Jupyter Notebook properly with well-commented code and structured markdowns, I am now more prepared to work collaboratively in a professional environment.
Improved Problem-olving Abilities: Each task required a different approach, helping me become more versatile and adaptive in solving data-related problems.
In conclusion, the internship gave me a well-rounded exposure to the entire data analysis process and prepared me for future opportunities in data science, machine learning, and business analytics.

